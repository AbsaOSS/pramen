# Copyright 2022 ABSA Group Limited
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

pramen {
  run.type = "(Prod)"
  environment.name = "MyEnv "${pramen.run.type}
  pipeline.name = "My DCE pipeline"

  parallel.tasks = 1

  bookkeeping.enabled = false

  warn.if.no.data = true
  email.if.no.changes = false

  # Jobs are T+1
  expected.delay.days = 1

  temporary.directory = "/tmp/pramen"

  warn.throughput.rps = 2000
  good.throughput.rps = 50000

  dry.run = false
}

mail {
  ## FILL IN THE SMTP SERVER HOST NAME IN ORDER O RECEIVE NOTIFICATION EMAILS
  smtp.host = ""
  smtp.port = "25"
  smtp.auth = "false"
  smtp.starttls.enable = "false"
  smtp.EnableSSL.enable = "false"
  debug = "false"

  send.from = "Pramen <pramen.noreply@absa.africa>"

  ## FILL IN EMAIL RECEPIENTS
  send.to = ""
}

pramen.metastore {
  tables = [
    {
      name = "my_table1"
      description = "My source table 1"
      format = "parquet"
      path = "/bigdata/datalake/landing/my_table1"
    },
    {
      name = "my_table2"
      description = "My source table 2"
      format = "delta"
      path = "/bigdata/datalake/landing/my_table2"
    }
  ]
}

pramen.sources = [
  {
    name = "postgre"
    factory.class = "za.co.absa.pramen.framework.source.JdbcSource"

    jdbc = {
      driver = "org.postgresql.Driver"
      connection.primary.url = "jdbc:postgresql://host/test_db"
      user = ""
      password = ""
    }

    option.fetchsize = 50000
    option.batchsize = 50000

    has.information.date.column = true

    information.date.column = "info_date"
    information.date.type = "date"
    information.date.app.format = "yyyy-MM-dd"
    information.date.sql.format = "YYYY-MM-DD"
  }
]

pramen.sinks = [
  {
    name = "dce"
    factory.class = "za.co.absa.pramen.builtin.sink.EnceladusSink"

    format = "csv"

    option {
      sep = "|"
      quoteAll = "false"
      header = "false"
    }

    mode = "overwrite"

    partition.pattern = "{year}/{month}/{day}/v{version}"

    records.per.partition = 1000000

    info.file {
      generate = true

      source.application = "MyApp"
      country = "Africa"
      history.type = "Snapshot"
      timestamp.format = "dd-MM-yyyy HH:mm:ss Z"
      date.format = "yyyy-MM-dd"
    }
  }
]

pramen.operations = [
  {
    name = "Table sourcing"
    type = "ingestion"
    schedule.type = "daily"

    #disabled = "true"

    source = "postgre"

    expected.delay.days = 1

    tables = [
      {
        input.db.table = my_table1
        output.metastore.table = my_table1
      },
      {
        input.db.table = my_table2
        output.metastore.table = my_table2

        # Optionally you can specify expressions for date ranges.
        #date.from = "@infoDate"
        #date.to = "@infoDate"
      }
    ]
  },
  {
    name = "DCE sink"
    type = "sink"
    sink = "dce"

    schedule.type = "daily"

    tables = [
      {
        input.metastore.table = my_table1
        output.path = "/bigdata/datalake/raw/my_table1"
        output.info.version = 1
      },
      {
        input.metastore.table = my_table2
        output.path = "/bigdata/datalake/raw/my_table2"
        output.info.version = 1
      }
    ]
  }
]
