# Copyright 2022 ABSA Group Limited
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This variable is expected to be set up by the test suite
#base.path = "/tmp"

pramen {
  pipeline.name = "Integration test with a file-based source"

  bookkeeping.enabled = false
  stop.spark.session = false
}

pramen.metastore {
  tables = [
    {
      name = "table1"
      description = "Table 1 (file based)"
      format = "raw"
      path = ${base.path}/table1
    }
  ]
}

pramen.sources.1 = [
  {
    name = "file_source"
    factory.class = "za.co.absa.pramen.core.source.RawFileSource"
  }
]

pramen.sinks.1 = [
  {
    name = "spark_sink"
    factory.class = "za.co.absa.pramen.core.sink.SparkSink"

    format = "parquet"
    mode = "overwrite"
  },
  {
    name = "post_proc"
    factory.class = "za.co.absa.pramen.core.mocks.sink.PostProcessingSink"
  }
]

pramen.operations = [
  {
    name = "Sourcing from a folder"
    type = "ingestion"
    schedule.type = "daily"

    source = "file_source"

    info.date.expr = "@runDate"

    tables = [
      {
        input.path = ${base.path}
        output.metastore.table = table1
      }
    ]
  },
  {
    # This sink depends on the ingestion job
    # table1->spark_sink <- (table1)
    name = "Sinking to parquet"
    type = "sink"

    sink = "spark_sink"

    schedule.type = "daily"

    output.table = "table2"

    tables = [
      {
        input.metastore.table = table1
        output.path = ${base.path}"/sink"
      }
    ]
  },
  {
    # This sink depends on the previous sink whith
    # "Sinking to parquet" -> "PostProcessing Sink 1"
    # post_sink2 <- (table1->spark_sink <- (table1))
    name = "PostProcessing Sink 1"
    type = "sink"

    sink = "post_proc"

    schedule.type = "daily"

    tables = [
      {
        # This is how you can define the tracking metastore table for a sink job.
        job.metastore.table = "post_sink2"

        # This is how a sink can depend on some other sink. You can use the 'generated tracking' metastore table.
        input.metastore.table = "table1->spark_sink"

        output.path = ${base.path}"/sink"
      }
    ]
  },
  {
    # This sink depends on the previous sink whith depends o the pre-previous sink
    # "Sinking to parquet" -> "PostProcessing Sink 1" -> "PostProcessing Sink 2"
    # post_sink2->post_proc <- (post_sink2 <- (table1->spark_sink <- (table1)))
    name = "PostProcessing Sink 2"
    type = "sink"

    sink = "post_proc"

    schedule.type = "daily"

    tables = [
      {
        # This is how a sink can depend on some other sink which has a tracking job table defined.
        input.metastore.table = "post_sink2"

        output.path = ${base.path}"/sink"
      }
    ]
  }
]
