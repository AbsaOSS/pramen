# Copyright 2022 ABSA Group Limited
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This variable is expected to be set up by the test suite
#base.path = "/tmp"
#fatal.exception = false

pramen {
  pipeline.name = "Integration test of parallel execution"

  bookkeeping.enabled = false
  stop.spark.session = false

  parallel.tasks = 4
}

pramen.metastore {
  tables = [
    {
      name = "table1"
      description = "Table 1"
      format = "parquet"
      path = ${base.path}/table1
    },
    {
      name = "table2"
      description = "Table 2"
      format = "parquet"
      path = ${base.path}/table2
    },
    {
      name = "table3"
      description = "Table 3"
      format = "parquet"
      path = ${base.path}/table3
    },
    {
      name = "table4"
      description = "Table 4"
      format = "parquet"
      path = ${base.path}/table4
    },
    {
      name = "table5"
      description = "Table 5"
      format = "parquet"
      path = ${base.path}/table5
    },
    {
      name = "table6"
      description = "Table 6"
      format = "parquet"
      path = ${base.path}/table6
    }
  ]
}

pramen.sources.1 = [
  {
    name = "spark_source"
    factory.class = "za.co.absa.pramen.core.source.SparkSource"

    has.information.date.column = false
  }
]

pramen.sinks.1 = [
  {
    name = "spark_sink"
    factory.class = "za.co.absa.pramen.core.sink.SparkSink"

    format = "parquet"
    mode = "overwrite"
  }
]

pramen.operations = [
  {
    name = "Loading data from Spark Catalog"
    type = "ingestion"
    schedule.type = "daily"

    source = "spark_source"

    info.date.expr = "@runDate"

    tables = [
      {
        input.table = "my_table1"
        output.metastore.table = "table1"
      }
    ]
  },
  {
    name = "Generate some data from the transformer"
    type = "transformation"

    class = "za.co.absa.pramen.core.mocks.transformer.GeneratingTransformer"
    schedule.type = "daily"

    info.date.expr = "@runDate"

    dependencies = [ ]

    output.table = "table2"
  },
  {
    name = "First transformation"
    type = "transformation"

    class = "za.co.absa.pramen.core.transformers.IdentityTransformer"
    schedule.type = "daily"

    info.date.expr = "@runDate"

    dependencies = [
      {
        tables = [ table2 ]
        date.from = "@infoDate"
        #optional = true
      }
    ]

    option {
      input.table = "table2"
    }

    output.table = "table3"
  },
  {
    name = "Failing transformation 1"
    type = "transformation"

    class = "za.co.absa.pramen.core.mocks.transformer.FailingTransformer"
    schedule.type = "daily"

    info.date.expr = "@runDate"

    dependencies = [
      {
        tables = [ table3 ]
        date.from = "@infoDate"
        #optional = true
      }
    ]

    option {
      fail.validation = true
      fatal.exception = ${fatal.exception}
    }

    output.table = "table4"
  },
  {
    name = "Failing transformation 2"
    type = "transformation"

    class = "za.co.absa.pramen.core.mocks.transformer.FailingTransformer"
    schedule.type = "daily"

    info.date.expr = "@runDate"

    dependencies = [
      {
        tables = [ table3 ]
        date.from = "@infoDate"
        #optional = true
      }
    ]

    option {
      fail.validation = false
      fatal.exception = ${fatal.exception}
    }

    output.table = "table5"
  },
  {
    name = "Failing transformation 3"
    type = "transformation"

    class = "za.co.absa.pramen.core.mocks.transformer.FailingTransformer"
    schedule.type = "daily"

    info.date.expr = "@runDate"

    dependencies = [
      {
        tables = [ table4 ]
        date.from = "@infoDate"
        #optional = true
      }
    ]

    option {
      fail.validation = false
      fatal.exception = false
    }

    output.table = "table6"
  },
  {
    name = "Sinking to parquet 1"
    type = "sink"
    sink = "spark_sink"
    schedule.type = "daily"

    tables = [
      {
        input.metastore.table = table3
        output.path = ${base.path}"/sink3"
      }
    ]
  },
  {
    name = "Sinking to parquet 2"
    type = "sink"
    sink = "spark_sink"
    schedule.type = "daily"

    tables = [
      {
        input.metastore.table = table4
        output.path = ${base.path}"/sink4"
      }
    ]
  },
  {
    name = "Sinking to parquet 3"
    type = "sink"
    sink = "spark_sink"
    schedule.type = "daily"

    tables = [
      {
        input.metastore.table = table5
        output.path = ${base.path}"/sink5"
      }
    ]
  }
]
